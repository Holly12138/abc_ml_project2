{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aVdrGb4h0kf5","executionInfo":{"status":"ok","timestamp":1671358180240,"user_tz":-60,"elapsed":2076,"user":{"displayName":"rongchen wang","userId":"07555551771397437419"}},"outputId":"065c123f-6c3a-4ddf-c2e1-64c7ef8d0e3c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import os\n","path =\"/content/drive/MyDrive/MLJR_1215_wang\"\n","os.chdir(path)\n","os.listdir(path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WN2DIftk0veU","executionInfo":{"status":"ok","timestamp":1671358184893,"user_tz":-60,"elapsed":238,"user":{"displayName":"rongchen wang","userId":"07555551771397437419"}},"outputId":"196a416a-3340-4bfe-f318-c104591ac0d1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['requirements.txt',\n"," 'metrics.py',\n"," 'README.md',\n"," 'mask_to_submission.py',\n"," 'functions.py',\n"," '.DS_Store',\n"," 'model.py',\n"," 'data_process.py',\n"," '__pycache__',\n"," 'test_set_images',\n"," 'training',\n"," 'result',\n"," 'Untitled0.ipynb',\n"," 'run.py']"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["!python run.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HACK_PmB0vha","outputId":"d0110207-4e50-4c85-dc74-23b85b9fdb1e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Namespace(batch_size=6, beta1=0.9, beta2=0.999, epochs=50, learning_rate=0.0003, loss='IoULoss', model='Res_Unet', prediction=True, scaler=0.5, use_model=False)\n","Loading 90 train images\n","tcmalloc: large alloc 2764800000 bytes == 0xf500a000 @  0x7f3b0c84d1e7 0x7f3b0973414e 0x7f3b097920b5 0x7f3b097926f9 0x7f3b0983520b 0x5aae14 0x4997c7 0x55d078 0x5d8941 0x4990ca 0x55cd91 0x55d743 0x642630 0x6426ae 0x644b78 0x64511c 0x677e5e 0x678029 0x7f3b0c44ac87 0x5e1baa\n","tcmalloc: large alloc 1382400000 bytes == 0x19aa40000 @  0x7f3b0c82fb6b 0x7f3b0c84f379 0x7f3a84a83935 0x7f3a84a61093 0x7f3ab1b354ca 0x7f3ab1b2d603 0x7f3ab1b2d65a 0x7f3ab1b2d6bf 0x7f3ab21d0469 0x7f3ab2c1f7b0 0x7f3ab2c1f810 0x7f3ab28dfb33 0x7f3ab2bf231e 0x7f3ab2922deb 0x7f3ab1e59ec7 0x7f3ab21c113b 0x7f3ab2dacb3b 0x7f3ab25fa425 0x7f3ab2bf2093 0x7f3ab25fa425 0x7f3ab3fb2a0b 0x7f3ab3fb2e7e 0x7f3ab267a989 0x7f3ab21b9517 0x7f3ab2f6af79 0x7f3ab27e1e8a 0x7f3adaba345b 0x7f3adaba443e 0x7f3adaba45b9 0x7f3adaba55e0 0x7f3adab681e9\n","After data processing, there are 720 train images\n","Loading 10 valid images\n","Start training\n","Total number of iterations = 6000\n","epoch 1 step 8 loss: 0.78534216 F1-score: 0.46982543640897756\n","epoch 1 step 16 loss: 0.78484863 F1-score: 0.43455324760962744\n","epoch 1 step 24 loss: 0.8235265 F1-score: 0.41222570532915365\n","epoch 1 step 32 loss: 0.7629039 F1-score: 0.48628335212326196\n","epoch 1 step 40 loss: 0.7100387 F1-score: 0.5145317545748116\n","epoch 1 step 48 loss: 0.63336754 F1-score: 0.6385110952040085\n","epoch 1 step 56 loss: 0.6751737 F1-score: 0.6007355946056395\n","epoch 1 step 64 loss: 0.75556874 F1-score: 0.4586739327883742\n","epoch 1 step 72 loss: 0.48964614 F1-score: 0.7791193181818182\n","epoch 1 step 80 loss: 0.6444824 F1-score: 0.6198166739415103\n","epoch 1 step 88 loss: 0.61227894 F1-score: 0.6607142857142857\n","epoch 1 step 96 loss: 0.5029252 F1-score: 0.784350256171402\n","epoch 1 step 104 loss: 0.58936226 F1-score: 0.6951774340309372\n","epoch 1 step 112 loss: 0.4839306 F1-score: 0.7836700336700337\n","epoch 1 step 120 loss: 0.5399058 F1-score: 0.7672955974842768\n","valid loss: 0.5009979 valid F1-score: 0.7396156230626163\n","epoch 2 step 8 loss: 0.5494025 F1-score: 0.6775464265616208\n","epoch 2 step 16 loss: 0.47086114 F1-score: 0.7565459610027855\n","epoch 2 step 24 loss: 0.50148827 F1-score: 0.7513924050632912\n","epoch 2 step 32 loss: 0.67500067 F1-score: 0.5658389766741911\n","epoch 2 step 40 loss: 0.4709084 F1-score: 0.7653701380175659\n","epoch 2 step 48 loss: 0.54158527 F1-score: 0.6798534798534798\n","epoch 2 step 56 loss: 0.6061121 F1-score: 0.6312900274473926\n","epoch 2 step 64 loss: 0.37201476 F1-score: 0.8411395461129888\n","epoch 2 step 72 loss: 0.5829339 F1-score: 0.6571897211591032\n","epoch 2 step 80 loss: 0.40430373 F1-score: 0.7956349206349207\n","epoch 2 step 88 loss: 0.53779984 F1-score: 0.7058823529411765\n","epoch 2 step 96 loss: 0.44467688 F1-score: 0.770516717325228\n","epoch 2 step 104 loss: 0.44221228 F1-score: 0.7577395577395577\n","epoch 2 step 112 loss: 0.36987686 F1-score: 0.7943342776203967\n","epoch 2 step 120 loss: 0.46285504 F1-score: 0.751099384344767\n","valid loss: 0.4109155 valid F1-score: 0.7912008654886404\n","epoch 3 step 8 loss: 0.49879962 F1-score: 0.7366959740860712\n","epoch 3 step 16 loss: 0.45407945 F1-score: 0.7926367081754195\n","epoch 3 step 24 loss: 0.52932847 F1-score: 0.6784810126582279\n","epoch 3 step 32 loss: 0.40729374 F1-score: 0.8090395480225989\n","epoch 3 step 40 loss: 0.41831785 F1-score: 0.7980475899938987\n","epoch 3 step 48 loss: 0.4111781 F1-score: 0.8130755064456722\n","epoch 3 step 56 loss: 0.37508512 F1-score: 0.8300000000000001\n","epoch 3 step 64 loss: 0.33377874 F1-score: 0.8466548253404381\n","epoch 3 step 72 loss: 0.41564304 F1-score: 0.8070652173913043\n","epoch 3 step 80 loss: 0.47853374 F1-score: 0.7237740533829919\n","epoch 3 step 88 loss: 0.4887091 F1-score: 0.7233789411064843\n","epoch 3 step 96 loss: 0.32060724 F1-score: 0.855025474756832\n","epoch 3 step 104 loss: 0.38209867 F1-score: 0.8198330878743251\n","epoch 3 step 112 loss: 0.3674702 F1-score: 0.822365165759525\n","epoch 3 step 120 loss: 0.2986982 F1-score: 0.890061565523307\n","valid loss: 0.40022868 valid F1-score: 0.813571178733823\n","epoch 4 step 8 loss: 0.50503606 F1-score: 0.7320441988950276\n","epoch 4 step 16 loss: 0.39543062 F1-score: 0.8107036669970267\n"]}]}]}